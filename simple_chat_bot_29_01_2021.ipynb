{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "simple_chat_bot_29.01.2021",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNYGQYZMJWmJnV+ughTElO0",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mb16biswas/simple_ai_chatbot/blob/main/simple_chat_bot_29_01_2021.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uTRFTUQz5vsj"
      },
      "source": [
        "#source of the data\r\n",
        "# https://www.techwithtim.net/tutorials/ai-chatbot/part-1/\r\n",
        "a = {\"intents\": [\r\n",
        "        {\"tag\": \"greeting\",\r\n",
        "         \"patterns\": [\"Hi\", \"How are you\", \"Is anyone there?\", \"Hello\", \"Good day\"],\r\n",
        "         \"responses\": [\"Hello, thanks for visiting\", \"Good to see you again\", \"Hi there, how can I help?\"],\r\n",
        "         \"context_set\": \"\"\r\n",
        "        },\r\n",
        "        {\"tag\": \"goodbye\",\r\n",
        "         \"patterns\": [\"Bye\", \"See you later\", \"Goodbye\"],\r\n",
        "         \"responses\": [\"See you later, thanks for visiting\", \"Have a nice day\", \"Bye! Come back again soon.\"]\r\n",
        "        },\r\n",
        "        {\"tag\": \"thanks\",\r\n",
        "         \"patterns\": [\"Thanks\", \"Thank you\", \"That's helpful\"],\r\n",
        "         \"responses\": [\"Happy to help!\", \"Any time!\", \"My pleasure\"]\r\n",
        "        },\r\n",
        "        {\"tag\": \"hours\",\r\n",
        "         \"patterns\": [\"What hours are you open?\", \"What are your hours?\", \"When are you open?\" ],\r\n",
        "         \"responses\": [\"We're open every day 9am-9pm\", \"Our hours are 9am-9pm every day\"]\r\n",
        "        },\r\n",
        "        {\"tag\": \"payments\",\r\n",
        "         \"patterns\": [\"Do you take credit cards?\", \"Do you accept Mastercard?\", \"Are you cash only?\" ],\r\n",
        "         \"responses\": [\"We accept VISA, Mastercard and AMEX\", \"We accept most major credit cards\"]\r\n",
        "        },\r\n",
        "        {\"tag\": \"opentoday\",\r\n",
        "         \"patterns\": [\"Are you open today?\", \"When do you open today?\", \"What are your hours today?\"],\r\n",
        "         \"responses\": [\"We're open every day from 9am-9pm\", \"Our hours are 9am-9pm every day\"]\r\n",
        "        }\r\n",
        "   ]\r\n",
        "}"
      ],
      "execution_count": 109,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nlog0Fy-Uycq"
      },
      "source": [
        "store = a "
      ],
      "execution_count": 110,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7y56-af66EpG"
      },
      "source": [
        "import tensorflow as tf\r\n",
        "\r\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\r\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense, Bidirectional\r\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\r\n",
        "from tensorflow.keras.models import Sequential\r\n",
        "from tensorflow.keras.optimizers import Adam\r\n",
        "import numpy as np \r\n"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-CXNNNaDAhhH"
      },
      "source": [
        "**Data processing ......**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CXZSZwZg6aej"
      },
      "source": [
        "store = a[\"intents\"]"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sAg44Pin8423"
      },
      "source": [
        "d = []\r\n",
        "for i in range(len(store)) : \r\n",
        "  c = store[i][\"patterns\"]\r\n",
        "  for j in range(len(c)):\r\n",
        "    d.append(c[j].lower())\r\n",
        " "
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nxI5GMG09DtE",
        "outputId": "1099191c-c14b-4610-b58a-abebf7a7720d"
      },
      "source": [
        "d"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['hi',\n",
              " 'how are you',\n",
              " 'is anyone there?',\n",
              " 'hello',\n",
              " 'good day',\n",
              " 'bye',\n",
              " 'see you later',\n",
              " 'goodbye',\n",
              " 'thanks',\n",
              " 'thank you',\n",
              " \"that's helpful\",\n",
              " 'what hours are you open?',\n",
              " 'what are your hours?',\n",
              " 'when are you open?',\n",
              " 'do you take credit cards?',\n",
              " 'do you accept mastercard?',\n",
              " 'are you cash only?',\n",
              " 'are you open today?',\n",
              " 'when do you open today?',\n",
              " 'what are your hours today?']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-GMvM6VA9fNE",
        "outputId": "2ea7b1cc-ecd7-43ea-bc7e-959631b7fa57"
      },
      "source": [
        "tokenizer = Tokenizer()\r\n",
        "tokenizer = Tokenizer()\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "corpus =  d \r\n",
        "\r\n",
        "tokenizer.fit_on_texts(corpus)\r\n",
        "tokenizer.fit_on_texts(corpus)\r\n",
        "total_words = len(tokenizer.word_index) + 1\r\n",
        "total_words= len(tokenizer.word_index) + 1 \r\n",
        "\r\n",
        "print(tokenizer.word_index)\r\n",
        "print(tokenizer.word_index)\r\n",
        "print(total_words)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'you': 1, 'are': 2, 'open': 3, 'what': 4, 'hours': 5, 'do': 6, 'today': 7, 'your': 8, 'when': 9, 'hi': 10, 'how': 11, 'is': 12, 'anyone': 13, 'there': 14, 'hello': 15, 'good': 16, 'day': 17, 'bye': 18, 'see': 19, 'later': 20, 'goodbye': 21, 'thanks': 22, 'thank': 23, \"that's\": 24, 'helpful': 25, 'take': 26, 'credit': 27, 'cards': 28, 'accept': 29, 'mastercard': 30, 'cash': 31, 'only': 32}\n",
            "{'you': 1, 'are': 2, 'open': 3, 'what': 4, 'hours': 5, 'do': 6, 'today': 7, 'your': 8, 'when': 9, 'hi': 10, 'how': 11, 'is': 12, 'anyone': 13, 'there': 14, 'hello': 15, 'good': 16, 'day': 17, 'bye': 18, 'see': 19, 'later': 20, 'goodbye': 21, 'thanks': 22, 'thank': 23, \"that's\": 24, 'helpful': 25, 'take': 26, 'credit': 27, 'cards': 28, 'accept': 29, 'mastercard': 30, 'cash': 31, 'only': 32}\n",
            "33\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mc-O1vI7AoY4"
      },
      "source": [
        "\r\n",
        "token_list = tokenizer.texts_to_sequences([corpus[2]])[0]"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LPkknkgeApIN",
        "outputId": "58e03375-1787-4dda-c4e5-cc3ec0875077"
      },
      "source": [
        "token_list"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[12, 13, 14]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hXn9jGXdFA8m"
      },
      "source": [
        "encode = []\r\n",
        "for i in corpus : \r\n",
        "\r\n",
        "  token = tokenizer.texts_to_sequences([i])[0]\r\n",
        "  encode.append(token)\r\n",
        "\r\n",
        "\r\n",
        " \r\n",
        "\r\n"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C-Dwo3gXFG0c",
        "outputId": "462e290e-7101-4c9c-ccad-9b95d0f375f3"
      },
      "source": [
        "encode "
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[10],\n",
              " [11, 2, 1],\n",
              " [12, 13, 14],\n",
              " [15],\n",
              " [16, 17],\n",
              " [18],\n",
              " [19, 1, 20],\n",
              " [21],\n",
              " [22],\n",
              " [23, 1],\n",
              " [24, 25],\n",
              " [4, 5, 2, 1, 3],\n",
              " [4, 2, 8, 5],\n",
              " [9, 2, 1, 3],\n",
              " [6, 1, 26, 27, 28],\n",
              " [6, 1, 29, 30],\n",
              " [2, 1, 31, 32],\n",
              " [2, 1, 3, 7],\n",
              " [9, 6, 1, 3, 7],\n",
              " [4, 2, 8, 5, 7]]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zi8P_Ou6F8PM"
      },
      "source": [
        "max_sequence_len = max([len(x) for x in encode])\r\n",
        "input_sequences = np.array(pad_sequences(encode , maxlen=max_sequence_len, padding='pre'))"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1utaUH9fGS0Z"
      },
      "source": [
        "new_encode = input_sequences "
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pn2gjuuoGVGV",
        "outputId": "5973d1e5-ea26-4345-f6bc-2626c92c1f09"
      },
      "source": [
        "new_encode "
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 0,  0,  0,  0, 10],\n",
              "       [ 0,  0, 11,  2,  1],\n",
              "       [ 0,  0, 12, 13, 14],\n",
              "       [ 0,  0,  0,  0, 15],\n",
              "       [ 0,  0,  0, 16, 17],\n",
              "       [ 0,  0,  0,  0, 18],\n",
              "       [ 0,  0, 19,  1, 20],\n",
              "       [ 0,  0,  0,  0, 21],\n",
              "       [ 0,  0,  0,  0, 22],\n",
              "       [ 0,  0,  0, 23,  1],\n",
              "       [ 0,  0,  0, 24, 25],\n",
              "       [ 4,  5,  2,  1,  3],\n",
              "       [ 0,  4,  2,  8,  5],\n",
              "       [ 0,  9,  2,  1,  3],\n",
              "       [ 6,  1, 26, 27, 28],\n",
              "       [ 0,  6,  1, 29, 30],\n",
              "       [ 0,  2,  1, 31, 32],\n",
              "       [ 0,  2,  1,  3,  7],\n",
              "       [ 9,  6,  1,  3,  7],\n",
              "       [ 4,  2,  8,  5,  7]], dtype=int32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FR9Ut1LYG4RC"
      },
      "source": [
        "d = []\r\n",
        "for i in new_encode:\r\n",
        "  c = i.astype(\"float32\")\r\n",
        "  d.append(c)\r\n",
        "\r\n",
        "new_encode = d"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wBVAH2PfHb5V",
        "outputId": "a8a94c36-7128-49a3-f0d2-b7d40fa9257c"
      },
      "source": [
        "for i in range(len(b)):\r\n",
        "  print(b[i][\"tag\"])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "greeting\n",
            "goodbye\n",
            "thanks\n",
            "hours\n",
            "payments\n",
            "opentoday\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k_sfct5mW1nV"
      },
      "source": [
        "#predictions \r\n",
        "y_train = [0,0,0,0,0,1,1,1,2,2,2,3,3,3,4,4,4,5,5,5]"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kthsLlzgW7xg",
        "outputId": "0781e672-caea-4f13-9568-3d4f65c36610"
      },
      "source": [
        "len(y_train) "
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "20"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4sT0ckm7SeUz"
      },
      "source": [
        "y_train_cat = tf.keras.utils.to_categorical(\r\n",
        "    y_train, num_classes = 6 , dtype='float32'\r\n",
        ")"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nYg3BsooW7GS"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zWcShb3RSvJ9",
        "outputId": "e7d64eb4-f947-4ee2-d807-9d552e6a03dd"
      },
      "source": [
        "y_train_cat"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1., 0., 0., 0., 0., 0.],\n",
              "       [1., 0., 0., 0., 0., 0.],\n",
              "       [1., 0., 0., 0., 0., 0.],\n",
              "       [1., 0., 0., 0., 0., 0.],\n",
              "       [1., 0., 0., 0., 0., 0.],\n",
              "       [0., 1., 0., 0., 0., 0.],\n",
              "       [0., 1., 0., 0., 0., 0.],\n",
              "       [0., 1., 0., 0., 0., 0.],\n",
              "       [0., 0., 1., 0., 0., 0.],\n",
              "       [0., 0., 1., 0., 0., 0.],\n",
              "       [0., 0., 1., 0., 0., 0.],\n",
              "       [0., 0., 0., 1., 0., 0.],\n",
              "       [0., 0., 0., 1., 0., 0.],\n",
              "       [0., 0., 0., 1., 0., 0.],\n",
              "       [0., 0., 0., 0., 1., 0.],\n",
              "       [0., 0., 0., 0., 1., 0.],\n",
              "       [0., 0., 0., 0., 1., 0.],\n",
              "       [0., 0., 0., 0., 0., 1.],\n",
              "       [0., 0., 0., 0., 0., 1.],\n",
              "       [0., 0., 0., 0., 0., 1.]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hC2XscWpFqA6"
      },
      "source": [
        "# shuffle  data \r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Et8opvLhdBEl"
      },
      "source": [
        "shuf = []\r\n",
        "for i in range(len(new_encode)):\r\n",
        "  shuf.append([new_encode[i] , y_train_cat[i]])"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n1xf4-zqGQYM"
      },
      "source": [
        "import random\r\n",
        "random.shuffle(shuf)"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yK6E9545IPvt",
        "outputId": "5286097a-6a02-4bd4-b10a-6d54a499259c"
      },
      "source": [
        "shuf"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[array([ 6.,  1., 26., 27., 28.], dtype=float32),\n",
              "  array([0., 0., 0., 0., 1., 0.], dtype=float32)],\n",
              " [array([4., 2., 8., 5., 7.], dtype=float32),\n",
              "  array([0., 0., 0., 0., 0., 1.], dtype=float32)],\n",
              " [array([0., 9., 2., 1., 3.], dtype=float32),\n",
              "  array([0., 0., 0., 1., 0., 0.], dtype=float32)],\n",
              " [array([ 0.,  0., 11.,  2.,  1.], dtype=float32),\n",
              "  array([1., 0., 0., 0., 0., 0.], dtype=float32)],\n",
              " [array([ 0.,  0.,  0., 16., 17.], dtype=float32),\n",
              "  array([1., 0., 0., 0., 0., 0.], dtype=float32)],\n",
              " [array([4., 5., 2., 1., 3.], dtype=float32),\n",
              "  array([0., 0., 0., 1., 0., 0.], dtype=float32)],\n",
              " [array([0., 2., 1., 3., 7.], dtype=float32),\n",
              "  array([0., 0., 0., 0., 0., 1.], dtype=float32)],\n",
              " [array([ 0.,  0.,  0., 23.,  1.], dtype=float32),\n",
              "  array([0., 0., 1., 0., 0., 0.], dtype=float32)],\n",
              " [array([ 0.,  6.,  1., 29., 30.], dtype=float32),\n",
              "  array([0., 0., 0., 0., 1., 0.], dtype=float32)],\n",
              " [array([ 0.,  0.,  0.,  0., 10.], dtype=float32),\n",
              "  array([1., 0., 0., 0., 0., 0.], dtype=float32)],\n",
              " [array([ 0.,  0.,  0.,  0., 15.], dtype=float32),\n",
              "  array([1., 0., 0., 0., 0., 0.], dtype=float32)],\n",
              " [array([ 0.,  0.,  0.,  0., 21.], dtype=float32),\n",
              "  array([0., 1., 0., 0., 0., 0.], dtype=float32)],\n",
              " [array([ 0.,  2.,  1., 31., 32.], dtype=float32),\n",
              "  array([0., 0., 0., 0., 1., 0.], dtype=float32)],\n",
              " [array([0., 4., 2., 8., 5.], dtype=float32),\n",
              "  array([0., 0., 0., 1., 0., 0.], dtype=float32)],\n",
              " [array([9., 6., 1., 3., 7.], dtype=float32),\n",
              "  array([0., 0., 0., 0., 0., 1.], dtype=float32)],\n",
              " [array([ 0.,  0., 12., 13., 14.], dtype=float32),\n",
              "  array([1., 0., 0., 0., 0., 0.], dtype=float32)],\n",
              " [array([ 0.,  0.,  0.,  0., 18.], dtype=float32),\n",
              "  array([0., 1., 0., 0., 0., 0.], dtype=float32)],\n",
              " [array([ 0.,  0., 19.,  1., 20.], dtype=float32),\n",
              "  array([0., 1., 0., 0., 0., 0.], dtype=float32)],\n",
              " [array([ 0.,  0.,  0.,  0., 22.], dtype=float32),\n",
              "  array([0., 0., 1., 0., 0., 0.], dtype=float32)],\n",
              " [array([ 0.,  0.,  0., 24., 25.], dtype=float32),\n",
              "  array([0., 0., 1., 0., 0., 0.], dtype=float32)]]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FeBfStMnIdoB"
      },
      "source": [
        "# train test splits \r\n",
        "\r\n",
        "X_train = []\r\n",
        "y_train = []\r\n",
        "\r\n",
        "for i in range(len(shuf)):\r\n",
        "  X_train.append(shuf[i][0])\r\n",
        "  y_train.append(shuf[i][1])\r\n"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gHF5JgN6I4P9"
      },
      "source": [
        "X_train = np.array(X_train)\r\n",
        "y_train = np.array(y_train)"
      ],
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W-Lc7nAYS9uS"
      },
      "source": [
        "model1 = tf.keras.Sequential([\r\n",
        "    tf.keras.layers.Embedding(total_words, 32 , input_length= max_sequence_len ),\r\n",
        "    tf.keras.layers.LSTM(32),\r\n",
        "    tf.keras.layers.Dense(6, activation=\"softmax\")\r\n",
        "])"
      ],
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VxnGt0MRaUlk"
      },
      "source": [
        "Both, categorical cross entropy and sparse categorical cross entropy have the same loss function which you have mentioned above. The only difference is the format in which you mention Yi (i,e true labels).\r\n",
        "\r\n",
        "If your Yi's are one-hot encoded, use categorical_crossentropy. Examples (for a 3-class classification): [1,0,0] , [0,1,0], [0,0,1]\r\n",
        "\r\n",
        "But if your Yi's are integers, use sparse_categorical_crossentropy. Examples for above 3-class classification problem: [1] , [2], [3]\r\n",
        "\r\n",
        "\r\n",
        "https://stats.stackexchange.com/questions/326065/cross-entropy-vs-sparse-cross-entropy-when-to-use-one-over-the-other"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pyNIEnr4YAE8"
      },
      "source": [
        "model1.compile(loss=\"categorical_crossentropy\",optimizer=\"rmsprop\",metrics=['acc'])"
      ],
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J_5OnfVxbOOh",
        "outputId": "0fb25cb7-38b6-4342-e314-85776f5c0a8e"
      },
      "source": [
        "model1.summary()"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding (Embedding)        (None, 5, 32)             1056      \n",
            "_________________________________________________________________\n",
            "lstm (LSTM)                  (None, 32)                8320      \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 6)                 198       \n",
            "=================================================================\n",
            "Total params: 9,574\n",
            "Trainable params: 9,574\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XrEALApZbuK6",
        "outputId": "31689079-6a93-4d4a-f48a-80447ba0c8a6"
      },
      "source": [
        "model1.fit(X_train , y_train , epochs= 100)"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.7823 - acc: 0.3500\n",
            "Epoch 2/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.7754 - acc: 0.2500\n",
            "Epoch 3/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.7689 - acc: 0.2500\n",
            "Epoch 4/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.7625 - acc: 0.2500\n",
            "Epoch 5/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.7559 - acc: 0.2500\n",
            "Epoch 6/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.7490 - acc: 0.2500\n",
            "Epoch 7/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.7417 - acc: 0.2500\n",
            "Epoch 8/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.7340 - acc: 0.2500\n",
            "Epoch 9/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.7258 - acc: 0.2500\n",
            "Epoch 10/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.7171 - acc: 0.2500\n",
            "Epoch 11/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.7079 - acc: 0.2500\n",
            "Epoch 12/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.6980 - acc: 0.2500\n",
            "Epoch 13/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 1.6874 - acc: 0.2500\n",
            "Epoch 14/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.6761 - acc: 0.2500\n",
            "Epoch 15/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.6641 - acc: 0.2500\n",
            "Epoch 16/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.6512 - acc: 0.2500\n",
            "Epoch 17/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.6376 - acc: 0.2500\n",
            "Epoch 18/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.6232 - acc: 0.4000\n",
            "Epoch 19/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.6080 - acc: 0.4000\n",
            "Epoch 20/100\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 1.5920 - acc: 0.4500\n",
            "Epoch 21/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1.5752 - acc: 0.4500\n",
            "Epoch 22/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.5578 - acc: 0.4500\n",
            "Epoch 23/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.5399 - acc: 0.4500\n",
            "Epoch 24/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.5215 - acc: 0.4500\n",
            "Epoch 25/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1.5027 - acc: 0.4500\n",
            "Epoch 26/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.4838 - acc: 0.4500\n",
            "Epoch 27/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.4648 - acc: 0.4000\n",
            "Epoch 28/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.4459 - acc: 0.4000\n",
            "Epoch 29/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.4271 - acc: 0.4000\n",
            "Epoch 30/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.4085 - acc: 0.4000\n",
            "Epoch 31/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1.3903 - acc: 0.4000\n",
            "Epoch 32/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1.3724 - acc: 0.5500\n",
            "Epoch 33/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 1.3549 - acc: 0.6000\n",
            "Epoch 34/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.3379 - acc: 0.6000\n",
            "Epoch 35/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1.3212 - acc: 0.6500\n",
            "Epoch 36/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.3050 - acc: 0.6000\n",
            "Epoch 37/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.2892 - acc: 0.6000\n",
            "Epoch 38/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.2738 - acc: 0.6000\n",
            "Epoch 39/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1.2588 - acc: 0.6000\n",
            "Epoch 40/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1.2442 - acc: 0.6000\n",
            "Epoch 41/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.2299 - acc: 0.6000\n",
            "Epoch 42/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.2159 - acc: 0.6000\n",
            "Epoch 43/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 1.2022 - acc: 0.6000\n",
            "Epoch 44/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1.1888 - acc: 0.6000\n",
            "Epoch 45/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 1.1755 - acc: 0.6000\n",
            "Epoch 46/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1.1625 - acc: 0.6000\n",
            "Epoch 47/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 1.1497 - acc: 0.6000\n",
            "Epoch 48/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.1371 - acc: 0.6000\n",
            "Epoch 49/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.1246 - acc: 0.6000\n",
            "Epoch 50/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 1.1122 - acc: 0.6000\n",
            "Epoch 51/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.0999 - acc: 0.6000\n",
            "Epoch 52/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.0878 - acc: 0.6000\n",
            "Epoch 53/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.0756 - acc: 0.6000\n",
            "Epoch 54/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1.0636 - acc: 0.6500\n",
            "Epoch 55/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1.0516 - acc: 0.6500\n",
            "Epoch 56/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.0396 - acc: 0.6500\n",
            "Epoch 57/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1.0277 - acc: 0.6500\n",
            "Epoch 58/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 1.0157 - acc: 0.6500\n",
            "Epoch 59/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.0038 - acc: 0.6500\n",
            "Epoch 60/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.9918 - acc: 0.6500\n",
            "Epoch 61/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.9799 - acc: 0.6500\n",
            "Epoch 62/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.9679 - acc: 0.7500\n",
            "Epoch 63/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.9559 - acc: 0.7500\n",
            "Epoch 64/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.9439 - acc: 0.7500\n",
            "Epoch 65/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.9318 - acc: 0.7500\n",
            "Epoch 66/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.9197 - acc: 0.7500\n",
            "Epoch 67/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.9075 - acc: 0.8500\n",
            "Epoch 68/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.8954 - acc: 0.8500\n",
            "Epoch 69/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.8831 - acc: 0.9000\n",
            "Epoch 70/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.8709 - acc: 0.9000\n",
            "Epoch 71/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.8586 - acc: 0.9000\n",
            "Epoch 72/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.8463 - acc: 0.9000\n",
            "Epoch 73/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.8340 - acc: 0.9500\n",
            "Epoch 74/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.8217 - acc: 0.9500\n",
            "Epoch 75/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.8094 - acc: 0.9500\n",
            "Epoch 76/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.7971 - acc: 0.9500\n",
            "Epoch 77/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.7848 - acc: 0.9500\n",
            "Epoch 78/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.7725 - acc: 0.9500\n",
            "Epoch 79/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.7603 - acc: 0.9500\n",
            "Epoch 80/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.7481 - acc: 0.9500\n",
            "Epoch 81/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.7359 - acc: 0.9500\n",
            "Epoch 82/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.7239 - acc: 0.9500\n",
            "Epoch 83/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.7118 - acc: 0.9500\n",
            "Epoch 84/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.7000 - acc: 0.9000\n",
            "Epoch 85/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.6890 - acc: 0.9000\n",
            "Epoch 86/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.6787 - acc: 0.9000\n",
            "Epoch 87/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.6673 - acc: 0.9000\n",
            "Epoch 88/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.6552 - acc: 0.9000\n",
            "Epoch 89/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.6438 - acc: 0.9000\n",
            "Epoch 90/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.6326 - acc: 0.9000\n",
            "Epoch 91/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.6217 - acc: 0.9000\n",
            "Epoch 92/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.6109 - acc: 0.9000\n",
            "Epoch 93/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.6001 - acc: 0.9500\n",
            "Epoch 94/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.5896 - acc: 0.9500\n",
            "Epoch 95/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.5791 - acc: 0.9500\n",
            "Epoch 96/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.5687 - acc: 0.9500\n",
            "Epoch 97/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.5586 - acc: 0.9500\n",
            "Epoch 98/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.5486 - acc: 0.9500\n",
            "Epoch 99/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.5389 - acc: 0.9500\n",
            "Epoch 100/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.5293 - acc: 0.9500\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f9b721685f8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QcuZL019cNNF"
      },
      "source": [
        "model2 = tf.keras.models.Sequential([\r\n",
        "                                  tf.keras.layers.Embedding(total_words, 32 , input_length= max_sequence_len),\r\n",
        "                                  tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(64)),\r\n",
        "                                  tf.keras.layers.Dense(64,activation= \"relu\"),\r\n",
        "                                  tf.keras.layers.Dense(6 , activation=\"softmax\")\r\n",
        "\r\n",
        "])\r\n",
        "model2.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
      ],
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YuRX_LBghj-2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fa8b01a0-2687-42a7-f607-170b2f332383"
      },
      "source": [
        "model2.summary()"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_1 (Embedding)      (None, 5, 32)             1056      \n",
            "_________________________________________________________________\n",
            "bidirectional (Bidirectional (None, 128)               49664     \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 64)                8256      \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 6)                 390       \n",
            "=================================================================\n",
            "Total params: 59,366\n",
            "Trainable params: 59,366\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U_qSaFtThro9",
        "outputId": "759c5344-c1bd-430d-810f-b23bdd23409c"
      },
      "source": [
        "model2.fit(X_train , y_train , epochs= 100)"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.7831 - accuracy: 0.4000\n",
            "Epoch 2/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.7780 - accuracy: 0.3500\n",
            "Epoch 3/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.7731 - accuracy: 0.3000\n",
            "Epoch 4/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.7679 - accuracy: 0.3000\n",
            "Epoch 5/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.7624 - accuracy: 0.3000\n",
            "Epoch 6/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.7563 - accuracy: 0.3000\n",
            "Epoch 7/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.7496 - accuracy: 0.3000\n",
            "Epoch 8/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.7423 - accuracy: 0.3000\n",
            "Epoch 9/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.7342 - accuracy: 0.3000\n",
            "Epoch 10/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.7254 - accuracy: 0.3000\n",
            "Epoch 11/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.7157 - accuracy: 0.3500\n",
            "Epoch 12/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.7050 - accuracy: 0.3500\n",
            "Epoch 13/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.6933 - accuracy: 0.3500\n",
            "Epoch 14/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.6805 - accuracy: 0.3500\n",
            "Epoch 15/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.6663 - accuracy: 0.3500\n",
            "Epoch 16/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.6509 - accuracy: 0.3500\n",
            "Epoch 17/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.6340 - accuracy: 0.3500\n",
            "Epoch 18/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1.6156 - accuracy: 0.3500\n",
            "Epoch 19/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 1.5957 - accuracy: 0.3500\n",
            "Epoch 20/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.5744 - accuracy: 0.4000\n",
            "Epoch 21/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 1.5516 - accuracy: 0.4000\n",
            "Epoch 22/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1.5277 - accuracy: 0.4000\n",
            "Epoch 23/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1.5026 - accuracy: 0.4500\n",
            "Epoch 24/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.4764 - accuracy: 0.4500\n",
            "Epoch 25/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 1.4496 - accuracy: 0.4000\n",
            "Epoch 26/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 1.4227 - accuracy: 0.4000\n",
            "Epoch 27/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1.3961 - accuracy: 0.4000\n",
            "Epoch 28/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1.3701 - accuracy: 0.4000\n",
            "Epoch 29/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1.3447 - accuracy: 0.4000\n",
            "Epoch 30/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1.3202 - accuracy: 0.4000\n",
            "Epoch 31/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1.2970 - accuracy: 0.4000\n",
            "Epoch 32/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 1.2738 - accuracy: 0.4000\n",
            "Epoch 33/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 1.2503 - accuracy: 0.4000\n",
            "Epoch 34/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1.2262 - accuracy: 0.4000\n",
            "Epoch 35/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 1.2019 - accuracy: 0.4000\n",
            "Epoch 36/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.1778 - accuracy: 0.4000\n",
            "Epoch 37/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1.1546 - accuracy: 0.4000\n",
            "Epoch 38/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1.1325 - accuracy: 0.4000\n",
            "Epoch 39/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 1.1120 - accuracy: 0.4000\n",
            "Epoch 40/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.0927 - accuracy: 0.4000\n",
            "Epoch 41/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1.0735 - accuracy: 0.4000\n",
            "Epoch 42/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 1.0535 - accuracy: 0.4500\n",
            "Epoch 43/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 1.0317 - accuracy: 0.5500\n",
            "Epoch 44/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 1.0087 - accuracy: 0.5500\n",
            "Epoch 45/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.9843 - accuracy: 0.5500\n",
            "Epoch 46/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.9599 - accuracy: 0.5500\n",
            "Epoch 47/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.9361 - accuracy: 0.6500\n",
            "Epoch 48/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.9125 - accuracy: 0.6500\n",
            "Epoch 49/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.8884 - accuracy: 0.7000\n",
            "Epoch 50/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.8627 - accuracy: 0.6500\n",
            "Epoch 51/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.8357 - accuracy: 0.6500\n",
            "Epoch 52/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.8083 - accuracy: 0.7000\n",
            "Epoch 53/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.7809 - accuracy: 0.7000\n",
            "Epoch 54/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.7527 - accuracy: 0.7000\n",
            "Epoch 55/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.7236 - accuracy: 0.7000\n",
            "Epoch 56/100\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.6935 - accuracy: 0.7000\n",
            "Epoch 57/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.6635 - accuracy: 0.7000\n",
            "Epoch 58/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.6345 - accuracy: 0.7000\n",
            "Epoch 59/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.6054 - accuracy: 0.7500\n",
            "Epoch 60/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.5758 - accuracy: 0.7500\n",
            "Epoch 61/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.5468 - accuracy: 0.7500\n",
            "Epoch 62/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.5189 - accuracy: 0.7500\n",
            "Epoch 63/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.4922 - accuracy: 0.8500\n",
            "Epoch 64/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.4667 - accuracy: 0.8500\n",
            "Epoch 65/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.4421 - accuracy: 0.8500\n",
            "Epoch 66/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.4184 - accuracy: 0.8500\n",
            "Epoch 67/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.3951 - accuracy: 0.9000\n",
            "Epoch 68/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.3724 - accuracy: 0.9000\n",
            "Epoch 69/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.3497 - accuracy: 0.9000\n",
            "Epoch 70/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.3270 - accuracy: 0.9500\n",
            "Epoch 71/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.3043 - accuracy: 1.0000\n",
            "Epoch 72/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.2814 - accuracy: 1.0000\n",
            "Epoch 73/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.2593 - accuracy: 1.0000\n",
            "Epoch 74/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.2373 - accuracy: 1.0000\n",
            "Epoch 75/100\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.2151 - accuracy: 1.0000\n",
            "Epoch 76/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.1936 - accuracy: 1.0000\n",
            "Epoch 77/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.1729 - accuracy: 1.0000\n",
            "Epoch 78/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.1530 - accuracy: 1.0000\n",
            "Epoch 79/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.1339 - accuracy: 1.0000\n",
            "Epoch 80/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.1160 - accuracy: 1.0000\n",
            "Epoch 81/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.0993 - accuracy: 1.0000\n",
            "Epoch 82/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.0837 - accuracy: 1.0000\n",
            "Epoch 83/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.0695 - accuracy: 1.0000\n",
            "Epoch 84/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.0569 - accuracy: 1.0000\n",
            "Epoch 85/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.0461 - accuracy: 1.0000\n",
            "Epoch 86/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0373 - accuracy: 1.0000\n",
            "Epoch 87/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0302 - accuracy: 1.0000\n",
            "Epoch 88/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.0246 - accuracy: 1.0000\n",
            "Epoch 89/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.0202 - accuracy: 1.0000\n",
            "Epoch 90/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.0168 - accuracy: 1.0000\n",
            "Epoch 91/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.0142 - accuracy: 1.0000\n",
            "Epoch 92/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0122 - accuracy: 1.0000\n",
            "Epoch 93/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.0106 - accuracy: 1.0000\n",
            "Epoch 94/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.0093 - accuracy: 1.0000\n",
            "Epoch 95/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.0082 - accuracy: 1.0000\n",
            "Epoch 96/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.0072 - accuracy: 1.0000\n",
            "Epoch 97/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.0065 - accuracy: 1.0000\n",
            "Epoch 98/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.0058 - accuracy: 1.0000\n",
            "Epoch 99/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.0052 - accuracy: 1.0000\n",
            "Epoch 100/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.0047 - accuracy: 1.0000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f9b6a8c5278>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LxUI1LdriuwY"
      },
      "source": [
        "prediction "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zNGGDZZlM-t9"
      },
      "source": [
        "#token_list = tokenizer.texts_to_sequences([corpus[2]])[0]\r\n",
        "def process(x):\r\n",
        "  token_list = tokenizer.texts_to_sequences([x])\r\n",
        "  input_sequences = np.array(pad_sequences(token_list , maxlen=max_sequence_len, padding='pre'))\r\n",
        "  input_sequences = np.array([input_sequences[0].astype(\"float32\")])\r\n",
        "  return input_sequences\r\n",
        "\r\n",
        "def num(x):\r\n",
        "  return random.randint(0,x-1)\r\n",
        "\r\n"
      ],
      "execution_count": 117,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UjbahPdPQiBK",
        "outputId": "37df7275-65fe-44f3-bdc8-e79e993e3d89"
      },
      "source": [
        "bot = True \r\n",
        "\r\n",
        "while bot :\r\n",
        "  print(\"..\")\r\n",
        "  x = input()\r\n",
        "  if x == \"quit\":\r\n",
        "    break\r\n",
        "  else:  \r\n",
        "    x = process(x)\r\n",
        "    x = model2.predict(x)\r\n",
        "    x = np.argmax(x[0])\r\n",
        "    if x == 0 :\r\n",
        "      b = store[\"intents\"][0][\"responses\"]\r\n",
        "      reply = num(len(b))\r\n",
        "      print(b[reply])\r\n",
        "        \r\n",
        "    elif x == 1 :\r\n",
        "\r\n",
        "      b = store[\"intents\"][1][\"responses\"]\r\n",
        "      reply = num(len(b))\r\n",
        "      print(b[reply])\r\n",
        "        \r\n",
        "    elif x == 2 :\r\n",
        "\r\n",
        "      b = store[\"intents\"][2][\"responses\"]\r\n",
        "      reply = num(len(b))\r\n",
        "      print(b[reply])\r\n",
        "        \r\n",
        "    elif x == 3 :\r\n",
        "      b = store[\"intents\"][3][\"responses\"]\r\n",
        "      reply = num(len(b))\r\n",
        "      print(b[reply])\r\n",
        "        \r\n",
        "    elif x == 4 :\r\n",
        "      b = store[\"intents\"][4][\"responses\"]\r\n",
        "      reply = num(len(b))\r\n",
        "      print(b[reply])\r\n",
        "      \r\n",
        "    else :\r\n",
        "      b = store[\"intents\"][5][\"responses\"]\r\n",
        "      reply = num(len(b))\r\n",
        "      print(b[reply])\r\n",
        "\r\n",
        "\r\n",
        "  \r\n"
      ],
      "execution_count": 120,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "..\n",
            "helloo\n",
            "Good to see you again\n",
            "..\n",
            "can u take payments\n",
            "Happy to help!\n",
            "..\n",
            "nicee\n",
            "Hello, thanks for visiting\n",
            "..\n",
            "goodbye\n",
            "Bye! Come back again soon.\n",
            "..\n",
            "hahhahahahh\n",
            "Hi there, how can I help?\n",
            "..\n",
            "quit\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}